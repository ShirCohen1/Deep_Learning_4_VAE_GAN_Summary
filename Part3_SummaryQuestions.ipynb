{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8WQ3xDQdq99"
   },
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{\\,\\middle\\vert\\,}\n",
    "\\newcommand{\\DKL}[2]{\\cset{D}_{\\text{KL}}\\left(#1\\,\\Vert\\, #2\\right)}\n",
    "\\newcommand{\\grad}[]{\\nabla}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "$$\n",
    "\n",
    "# Part 3: Summary Questions\n",
    "<a id=part2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG8cCFaJdq-B"
   },
   "source": [
    "This section contains summary questions about various topics from the course material.\n",
    "\n",
    "You can add your answers in new cells below the questions.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "- Clearly mark where your answer begins, e.g. write \"**Answer:**\" in the beginning of your cell.\n",
    "- Provide a full explanation, even if the question doesn't explicitly state so. We will reduce points for partial explanations!\n",
    "- This notebook should be runnable from start to end without any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62PGMRFjdq-C"
   },
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVd9d9Ikdq-C"
   },
   "source": [
    "1. Explain the meaning of the term \"receptive field\" in the context of CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbo6Y2pejsem"
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "The receptive field defined as the region of the input space that affects a particular CNN's unit of the network. This input region can be not only the input of the network but also output from other units in the network, therefore this receptive field can be calculated relative to the input that we consider and also relative the unit that we are taking into consideration as the “receiver” of this input region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRYYGOQudq-C"
   },
   "source": [
    "2. Explain and elaborate about three different ways to control the rate at which the receptive field grows from layer to layer. Compare them to each other in terms of how they combine input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH4h5nGHkmSV"
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "* Add more convolutional layers (make the network deeper) - increases the \n",
    "receptive field size linearly, as each extra layer increases the receptive field size by the kernel size\n",
    "\n",
    "* Add pooling layers or higher stride convolutions (sub-sampling) - increases the receptive field size multiplicatively. sequentially placed dilated convolutions, increase the RF exponentially.\n",
    "\n",
    "* Depth-wise convolutions - the receptive field is increased with a small compute footprint, so it is considered a compact way to increase the receptive field with fewer parameters. this technique do not directly increase the receptive field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtchF_XJdq-D"
   },
   "source": [
    "3. Imagine a CNN with three convolutional layers, defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-26T09:18:16.753322Z",
     "iopub.status.busy": "2021-01-26T09:18:16.752610Z",
     "iopub.status.idle": "2021-01-26T09:18:17.987501Z",
     "shell.execute_reply": "2021-01-26T09:18:17.988034Z"
    },
    "executionInfo": {
     "elapsed": 8162,
     "status": "ok",
     "timestamp": 1645557366527,
     "user": {
      "displayName": "Shir Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxzgFCwcO2VgDEyrWnLAS5HsXbQDYe4JILsIFVgN4=s64",
      "userId": "04622715026667402457"
     },
     "user_tz": -120
    },
    "id": "JpdxT0Xkdq-D",
    "outputId": "16fd8e6c-6502-4be4-ebec-41c3328bc3f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 122, 122])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=4, out_channels=16, kernel_size=5, stride=2, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=7, dilation=2, padding=3),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "cnn(torch.rand(size=(1, 3, 1024, 1024), dtype=torch.float32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MJQnIyndq-F"
   },
   "source": [
    "What is the size (spatial extent) of the receptive field of each \"pixel\" in the output tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT-V0wA13J3G"
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "To calculate the size of the receptive field of each pixel, \n",
    "we will use the formula $[r_{0}=\\sum_{l=1}^{L}\\left(\\left(k_{l}-1\\right) \\prod_{i=1}^{l-1} s_{i}\\right)+1]$, where $r_0$ is the output layer receptive field. \n",
    "We will implemnt the calculations below with\n",
    "K = kernels, S = strides, D = dialtions\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1645564805958,
     "user": {
      "displayName": "Shir Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxzgFCwcO2VgDEyrWnLAS5HsXbQDYe4JILsIFVgN4=s64",
      "userId": "04622715026667402457"
     },
     "user_tz": -120
    },
    "id": "f5Kpi0bKSUPd",
    "outputId": "6acea27c-714a-4d03-a6a3-5a35ff0263ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the receptive field of each pixel in the output tensor is 111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_layers = 5\n",
    "K = [3, 2, 5, 2, 7]\n",
    "S = [1, 2, 2, 2, 1]\n",
    "D = [1, 1, 1, 1, 2]\n",
    "r_0 = 1\n",
    "\n",
    "for l in range(num_layers):\n",
    "    layer_sum = 1\n",
    "    for i in range(l):\n",
    "        layer_sum = layer_sum * S[i]\n",
    "        r_0 += (K[l] - 1) * layer_sum\n",
    "\n",
    "print(f\"The size of the receptive field of each pixel in the output tensor is {r_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Off3jlnXdq-G"
   },
   "source": [
    "4. You have trained a CNN, where each layer $l$ is represented by the mapping $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)$, and $f_l(\\cdot;\\vec{\\theta}_l)$ is a convolutional layer (not including the activation function).\n",
    "\n",
    "  After hearing that residual networks can be made much deeper, you decide to change each layer in your network you used the following residual mapping instead $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)+\\vec{x}$, and re-train.\n",
    "\n",
    "  However, to your surprise, by visualizing the learned filters $\\vec{\\theta}_l$ you observe that the original network and the residual network produce completely different filters. Explain the reason for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUy3e1nZnpkd"
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "The x input has a significant affect on the filters that were learned.\n",
    "Since we changed the expression to learn also the residual block, it also changed the real output of the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpDQ7Ljedq-G"
   },
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4QIkiTedq-L"
   },
   "source": [
    "1. Consider the following neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-26T09:18:17.992615Z",
     "iopub.status.busy": "2021-01-26T09:18:17.991868Z",
     "iopub.status.idle": "2021-01-26T09:18:18.013482Z",
     "shell.execute_reply": "2021-01-26T09:18:18.014164Z"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1645557623986,
     "user": {
      "displayName": "Shir Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxzgFCwcO2VgDEyrWnLAS5HsXbQDYe4JILsIFVgN4=s64",
      "userId": "04622715026667402457"
     },
     "user_tz": -120
    },
    "id": "QNpYiklsdq-L",
    "outputId": "3f620207-6b2f-401f-c0f5-57f395132440"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.1, inplace=False)\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "p1, p2 = 0.1, 0.2\n",
    "nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p1),\n",
    "    nn.Dropout(p=p2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRlC4o14dq-M"
   },
   "source": [
    "If we want to replace the two consecutive dropout layers with a single one defined as follows:\n",
    "```python\n",
    "nn.Dropout(p=q)\n",
    "```\n",
    "what would the value of `q` need to be? Write an expression for `q` in terms of `p1` and `p2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvOCOboepTL5"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "Given that the layers are indepedent from each other, if a weight is dropped (zeroed) in the first dropout layer this is probability p1. If the weight still survives the first layer but then gets dropped in the second, this is probability (1-p1)*p2. \n",
    "Thus, the final expressions is: $q = p1 + (1-p1)*p2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6fqYbqFdq-M"
   },
   "source": [
    "2. **True or false**: dropout must be placed only after the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_ilmGZNq21q"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "True, given dropout of p, the dropout layer wil set every hidden unit to 0 in probability of p. This should be done after the activation function which converts the range of the hidden units to [-1,1] or [0,1] depending on the activation function. If dropout is performed before activation then on the hidden units that have been \"dropped\" we will apply activation and this can technically \"re-activate\" their value if we are not careful of the calculation. For example if a hidden unit has value x then is dropped to 0, then activation sigmoid(0) = 0.5 is applied. Final value will be 0.5. In the other order, we get sigmoid(x) that is passed to dropout so its final value is 0. Final value of 0 is the expected default value.  \n",
    "This is not the case for relu since dropout(relu(x)) = relu(dropout(x)) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp0tJNZSdq-M"
   },
   "source": [
    "3. After applying dropout with a drop-probability of $p$, the activations are scaled by $1/(1-p)$. Prove that this scaling is required in order to maintain the value of each activation unchanged in expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9DUJ6icskBE"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "Let A(x):= activation of a given unit x. The expectation without any dropout is A(x). When dropout with probability p is used, then for a given x we are de-activating the unit with probability p. So in this case E = (1-p)A(x) + p*0; there is probability 1-p we remain with activation value and probability p that 0(A(x)) = 0 de-activated.\n",
    "\n",
    "In order for E = A(x) we need to scale by 1/(1-p). Then\n",
    "E = (1-p)(A(x)/(1-p)) + p*0 = A(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5gYukt7dq-N"
   },
   "source": [
    "### Losses and Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoSyEr2Ddq-N"
   },
   "source": [
    "1. You're training a an image classifier that, given an image, needs to classify it as either a dog (output 0) or a hotdog (output 1). Would you train this model with an L2 loss? if so, why? if not, demonstrate with a numerical example. What would you use instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sdzE2_hvh_P"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "Should use binary cross entropy: −(ylog(p)+(1−y)log(1−p))\n",
    "\n",
    "\n",
    "If output is a dog and model returns 1 (hotdog) -> L2 norm = 1\n",
    "All wrong answers for N samples: L2 loss = sqrt(N).\n",
    "Doesnt differentiate between how big the error is based on the intial probabilities (p , 1-p) and not just the final class output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyhGgPyVdq-N"
   },
   "source": [
    "2. After months of research into the origins of climate change, you observe the following result:\n",
    "\n",
    "<center><img src=\"https://sparrowism.soc.srcf.net/home/piratesarecool4.gif\" /></center>\n",
    "\n",
    "You decide to train a cutting-edge deep neural network regression model, that will predict the global temperature based on the population of pirates in `N` locations around the globe.\n",
    "You define your model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T09:18:18.019108Z",
     "iopub.status.busy": "2021-01-26T09:18:18.018447Z",
     "iopub.status.idle": "2021-01-26T09:18:18.042969Z",
     "shell.execute_reply": "2021-01-26T09:18:18.043669Z"
    },
    "id": "hSTpCN8jdq-N"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N = 42  # number of known global pirate hot spots\n",
    "H = 128\n",
    "mlpirate = nn.Sequential(\n",
    "    nn.Linear(in_features=N, out_features=H),\n",
    "    nn.Sigmoid(),\n",
    "    *[\n",
    "        nn.Linear(in_features=H, out_features=H), nn.Sigmoid(),\n",
    "    ]*24,\n",
    "    nn.Linear(in_features=H, out_features=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdlzVMuRdq-O"
   },
   "source": [
    "While training your model you notice that the loss reaches a plateau after only a few iterations.\n",
    "It seems that your model is no longer training.\n",
    "What is the most likely cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_5wMcHWySBS"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "The most likely cause is vanishing gradients. The model has 26 linear layers and the activation function chosen will cause small gradients that will eventually zero out during backpropogration. This will effectively prevent the weights from updating and the training will stop as a result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgpeD_Widq-O"
   },
   "source": [
    "3. Referring to question 2 above: A friend suggests that if you replace the `sigmoid` activations with `tanh`, it will solve your problem. Is he correct? Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW5UFncwzYcL"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "While the derivatives of the tanh are larger than the derivatives of the sigmoid, this may not be enough to fix the problem. Tanh has a maximum derivative of 1 and this may help us in training. But overall it faces the same vanishing gradient issue, which will likely be the case in a deep network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pCsXHg4dq-O"
   },
   "source": [
    "4. Regarding the ReLU activation, state whether the following sentences are **true or false** and explain:\n",
    "  1. In a model using exclusively ReLU activations, there can be no vanishing gradients.\n",
    "  1. The gradient of ReLU is linear with its input when the input is positive.\n",
    "  1. ReLU can cause \"dead\" neurons, i.e. activations that remain at a constant value of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Z4_w9oHzcIS"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. True: The derivative of the Relu function is either 0 or 1. During backpropogation as long as we are multipliying by value 1, there is no issue with vanishing gradient value.\n",
    "2. False: For input x > 0, Relu(x) = x. The gradient here is 1, which is linear (constant). For x <= 0, Relu(x) = 0 so gradient is 0, also a linear constant. \n",
    "3. True: If every training example causes a certain neuron to have a negative value (which then becomes 0 after ReLU is applied), then the neuron will never be adjusted, since no matter which training example is selected (or which batch) the gradient on the neuron will be 0. Thus, the neuron can be \"dead\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PR1IQtedq-O"
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhOjhaVzdq-O"
   },
   "source": [
    "1. Explain the difference between: stochastic gradient descent (SGD), mini-batch SGD and regular gradient descent (GD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLoUlZ9x0rOQ"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "- SGD: Computes gradient for each sample one at a time. If there are 100 samples in dataset then the gradient and loss are calculated 100 times in a single epoch. An update per sample.\n",
    "- Mini-batch SGD: Computes the gradient for one batch at a time, overall all samples are computed. If there are 100 samples in dataset and 20 mini batches with 5 samples in each, then the gradient is calculated 20 times in a single epoch. An update per batch.\n",
    "- GD: Computed gradient for all samples at once. An update per all samples. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97c6NLpcdq-P"
   },
   "source": [
    "2. Regarding SGD and GD:\n",
    "  1. Provide at least two reasons for why SGD is used more often in practice compared to GD.\n",
    "  2. In what cases can GD not be used at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38rpQ4F31F7P"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. The reasons that SGD is used more often comaped to GD are:\n",
    "- In each update it is faster to compute on one sample vs all samples at once,\n",
    "GD takes a fewer number of updates but each update is done actually after one whole epoch. SGD takes a lot of update steps but it will take a lesser number of epochs i.e. the number of times we iterate through all examples will be lesser in this case and thus it is a much faster process.\n",
    "\n",
    "- Easier to move out of local minimum when training on one sample at a time. In cases where using GD we may get stuck on local minimum and due to learning rate may not be able to converge to global minimum. \n",
    "\n",
    "2. When we are working with very large datasets, it may not be possible to even calculate gradients for all samples at once. There may not be enough memory or processing power to perform a single update. To solve this we can use mini-batch SGD or SGD and use a dataloader. The dataloader will only load to memory the samples that are being calculated at a given time, this will save memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibD1Z-8Bdq-P"
   },
   "source": [
    "3. You have trained a deep resnet to obtain SoTA results on ImageNet.\n",
    "While training using mini-batch SGD with a batch size of $B$, you noticed that your model converged to a loss value of $l_0$ within $n$ iterations (batches across all epochs) on average.\n",
    "Thanks to your amazing results, you secure funding for a new high-powered server with GPUs containing twice the amount of RAM.\n",
    "You're now considering to increase the mini-batch size from $B$ to $2B$.\n",
    "Would you expect the number of of iterations required to converge to $l_0$ to decrease or increase when using the new batch size? explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqXoGbjbZoGW"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "If we increase batch size, this may not neccesarily lead to better results in same number of iterations. Since we already have good results with batch size B, adding more samples can cause the model to generalize which leads to lower accuracy and slower learning.  \n",
    "\n",
    "The reason for this could be that during each mini-batch the gradients are averaged out. If there are too many samples in the batch the model will over generalize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2jJJ60cdq-P"
   },
   "source": [
    "4. For each of the following statements, state whether they're **true or false** and explain why.\n",
    "  1. When training a neural network with SGD, every epoch we perform an optimization step for each sample in our dataset.\n",
    "  1. Gradients obtained with SGD have less variance and lead to quicker convergence compared to GD.\n",
    "  1. SGD is less likely to get stuck in local minima, compared to GD.\n",
    "  1. Training  with SGD requires more memory than with GD.\n",
    "  1. Assuming appropriate learning rates, SGD is guaranteed to converge to a local minimum, while GD is guaranteed to converge to the global minimum.\n",
    "  1. Given a loss surface with a narrow ravine (high curvature in one direction): SGD with momentum will converge more quickly than Newton's method which doesn't have momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKbJq5CqZvGF"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. True : In SGD the optimization step is performed for each sample per epoch.\n",
    "2. False : Gradients have more variance/ more noisy since they are only based on one sample at a time. In GD the gradients at each update are averaged so there is less fluctuation. However, there is quicker convergence in SGD compared to GD.\n",
    "3. True : Since the losses of SGD fluctuate more, it is more likely that we will not get stuck in local minimi during training. \n",
    "4. False : Only 1 sample and its calculations need to be stored in memory at a given time.\n",
    "5. False : GD is not guaranteed to converge to global minimum. This will depend on loss function (convexity) and learning rate. SGD does converge to local minimum.\n",
    "6. True : SGD with momentum will converge faster. SGD with Newton's method will tend to oscillate across the narrow ravine since the negative gradient will point down one of the steep sides rather than along the ravine towards the optimum. Momentum helps accelerate gradients in the right direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1QBhw3pdq-P"
   },
   "source": [
    "5. **Bonus** (we didn't discuss this at class):  We can use bi-level optimization in the context of deep learning, by embedding an optimization problem as a layer in the network.\n",
    "  **True or false**: In order to train such a network, the inner optimization problem must be solved with a descent based method (such as SGD, LBFGS, etc).\n",
    "  Provide a mathematical justification for your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8YPHVXrdq-P"
   },
   "source": [
    "6. You have trained a neural network, where each layer $l$ is represented by the mapping $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)$ for some arbitrary parametrized functions $f_l(\\cdot;\\vec{\\theta}_l)$.\n",
    "  Unfortunately while trying to break the record for the world's deepest network, you discover that you are unable to train your network with more than $L$ layers.\n",
    "  1. Explain the concepts of \"vanishing gradients\", and \"exploding gradients\".\n",
    "  2. How can each of these problems be caused by increased depth?\n",
    "  3. Provide a numerical example demonstrating each.\n",
    "  4. Assuming your problem is either of these, how can you tell which of them it is without looking at the gradient tensor(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9mM0js9-ZBF"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. Vanishing gradients occurs when the derivative or slope will get smaller and smaller as we go backward with every layer during backpropagation. \n",
    "this problem occurs with the sigmoid and tanh activation function because the derivatives of the sigmoid and tanh activation functions are between 0 to 0.25 and 0–1 because the weights update is very small or exponential small, the training time takes too much longer, and in the worst case, this may completely stop the neural network training.\n",
    "\n",
    "  Exploding gradients occurs when the derivatives or slope will get larger and larger as we go backward with every layer during backpropagation. This situation is the exact opposite of the vanishing gradients and happens because of the weights and not the activation function. \n",
    "\n",
    "2. The more we multiply smaller/bigger numbers due to increased depth, the more chances the can run into these problems. \n",
    "\n",
    "\n",
    "3. For example: If we have a derivative value of 0.001, then in a 2 layer network, after backpropogation 2 times we get a value of $0.001^2$. \n",
    "But if we have the same derivative in a 100 layer network, after backpropogation of all layers we get a value of $0.001^{100}$. This is a very small number that can cause a vanishing gradient.  \n",
    "  In the opposite direction if we have a large gradient of 2, and a 2 layer network the result after backpropogation is $2^2$. We can update the weights with value 4. But in an 100 layer network, a final value of $2^{100}$ will cause the gradient to explode. $2^{100}$ is numerically too big to use and to calculate in context with the rest of the calculations.\n",
    "\n",
    "4. If the model learns very slowly and perhaps the training stagnates at a very early stage just after a few iterations then the issue is likely vanishing gradient. If the model has a poor loss or the model displays NaN loss whilst training then the issue is likely an exploding gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpBuXUDddq-P"
   },
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mA7-pBYdq-P"
   },
   "source": [
    "1. You wish to train the following 2-layer MLP for a binary classification task:\n",
    "  $$\n",
    "  \\hat{y}^{(i)} =\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2\n",
    "  $$\n",
    "  Your wish to minimize the in-sample loss function is defined as\n",
    "  $$\n",
    "  L_{\\mathcal{S}} = \\frac{1}{N}\\sum_{i=1}^{N}\\ell(y^{(i)},\\hat{y}^{(i)}) + \\frac{\\lambda}{2}\\left(\\norm{\\mat{W}_1}_F^2 + \\norm{\\mat{W}_2}_F^2 \\right)\n",
    "  $$\n",
    "  Where the pointwise loss is binary cross-entropy:\n",
    "  $$\n",
    "  \\ell(y, \\hat{y}) =  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})\n",
    "  $$\n",
    "  \n",
    "  Write an analytic expression for the derivative of the final loss $L_{\\mathcal{S}}$ w.r.t. each of the following tensors: $\\mat{W}_1$, $\\mat{W}_2$, $\\mat{b}_1$, $\\mat{b}_2$, $\\mat{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTV1VUMy17U2"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "$ \\frac{\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2 - y}{(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2)(1-(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2))}$\n",
    "\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_1} = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2 - y}{(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2)(1-(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2))}*(W_2\\varphi'(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1)x^{(i)} + \\lambda\\norm{\\mat{W}_1}_F' $\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_2} = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2 - y}{(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2)(1-(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2))}*(\\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1)) + \\lambda\\norm{\\mat{W}_2}_F' $\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b_1} = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2 - y}{(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2)(1-(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2))}*(W_2\\varphi'(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) $\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b_2} = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2 - y}{(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2)(1-(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2))} $\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x} = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2 - y}{(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2)(1-(\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2))}*(W_2\\varphi'(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1)W_1) $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRGzjVnXdq-Q"
   },
   "source": [
    "2. The derivative of a function $f(\\vec{x})$ at a point $\\vec{x}_0$ is\n",
    "  $$\n",
    "  f'(\\vec{x}_0)=\\lim_{\\Delta\\vec{x}\\to 0} \\frac{f(\\vec{x}_0+\\Delta\\vec{x})-f(\\vec{x}_0)}{\\Delta\\vec{x}}\n",
    "  $$\n",
    "  \n",
    "  1. Explain how this formula can be used in order to compute gradients of neural network parameters numerically, without automatic differentiation (AD).\n",
    "  \n",
    "  2. What are the drawbacks of this approach? List at least two drawbacks compared to AD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWLQbTyoA4GT"
   },
   "source": [
    "**Answer**\n",
    "1. Instead of using the formulas calculated above and the chain rule, we can go ahead and calculate the derivative values empirically with the limit equation above. \n",
    "\n",
    "2. For every derivative have to evaluate 2 functions instead of 1 so its more resources. It lead to roundoff errors in the discretization process and cancellation. It is also slow at computing partial derivatives of a function with respect to many inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0BoEqzgdq-Q"
   },
   "source": [
    "3. Given the following code snippet:\n",
    "  1. Write a short snippet that implements that calculates gradient of `loss` w.r.t. `W` and `b` using the approach of numerical gradients from the previous question.\n",
    "  2. Calculate the same derivatives with autograd.\n",
    "  3. Show, by calling `torch.allclose()` that your numerical gradient is close to autograd's gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-26T09:18:18.049487Z",
     "iopub.status.busy": "2021-01-26T09:18:18.048852Z",
     "iopub.status.idle": "2021-01-26T09:18:18.072993Z",
     "shell.execute_reply": "2021-01-26T09:18:18.073616Z"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1645864985880,
     "user": {
      "displayName": "Dana Gorovici",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03883066315521848737"
     },
     "user_tz": -120
    },
    "id": "QCtPEVOJdq-Q",
    "outputId": "2677db45-acf6-4821-b1d6-850b9967757a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=1.8899954468598215\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import grad\n",
    "import torch\n",
    "\n",
    "N, d = 100, 5\n",
    "dtype = torch.float64\n",
    "X = torch.rand(N, d, dtype=dtype)\n",
    "W, b = torch.rand(d, d, requires_grad=True, dtype=dtype), torch.rand(d, requires_grad=True, dtype=dtype)\n",
    "\n",
    "def foo(W, b):\n",
    "    return torch.mean(X @ W + b)\n",
    "\n",
    "loss = foo(W, b)\n",
    "print(f\"loss={loss}\")\n",
    "\n",
    "# TODO: Calculate gradients numerically for W and b\n",
    "grad_W = torch.zeros_like(W)\n",
    "grad_b = torch.zeros_like(b)\n",
    "delta = 2e-8\n",
    "\n",
    "for i in range(0,d):\n",
    "  for j in range(0,d):\n",
    "    w_new = W.clone()\n",
    "    w_new[i,j] += delta\n",
    "    grad_W[i,j] = (foo(w_new,b)-foo(W,b))/delta\n",
    "\n",
    "for i in range(0,d):\n",
    "  b_new = b.clone()\n",
    "  b_new[i] += delta\n",
    "  grad_b[i] = (foo(W,b_new)-foo(W,b))/delta\n",
    "\n",
    "# TODO: Compare with autograd using torch.allclose()\n",
    "loss.backward()\n",
    "autograd_W = W.grad\n",
    "autograd_b = b.grad\n",
    "\n",
    "assert torch.allclose(grad_W, autograd_W)\n",
    "assert torch.allclose(grad_b, autograd_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFgkvYZidq-Q"
   },
   "source": [
    "### Sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imO7budhdq-Q"
   },
   "source": [
    "1. Regarding word embeddings:\n",
    "  1. Explain this term and why it's used in the context of a language model.\n",
    "  1. Can a language model like the sentiment analysis example from the tutorials be trained without an embedding (i.e. trained directly on sequences of tokens)? If yes, what would be the consequence for the trained model? if no, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw0RgOyKFhD_"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. Word embedding is a representation of a word in D dimensional vector space. Used to reduce dimension of input from 1-hot encoding which is size of vocabulary to a smaller D dimension. Embedding layer enables us to convert each word into a fixed length vector of defined size. The resultant vector is a dense one with having real values instead of just 0’s and 1’s.\n",
    "2. Using only the 1-hot encoding is not a feasible embedding approach as it demands large storage space for the word vectors and reduces model efficiency. The 1-hot vector is very sparse and most of the time would not yield good results compared to the embedding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjdDEAQUdq-R"
   },
   "source": [
    "2. Considering the following snippet, explain:\n",
    "  1. What does `Y` contain? why this output shape?\n",
    "  2. **Bonus**: How you would implement `nn.Embedding` yourself using only torch tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-26T09:18:18.077958Z",
     "iopub.status.busy": "2021-01-26T09:18:18.077299Z",
     "iopub.status.idle": "2021-01-26T09:18:18.378980Z",
     "shell.execute_reply": "2021-01-26T09:18:18.379850Z"
    },
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1645865776504,
     "user": {
      "displayName": "Dana Gorovici",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03883066315521848737"
     },
     "user_tz": -120
    },
    "id": "0UT3KK15dq-R",
    "outputId": "118237eb-2647-41a1-d6be-6adb8de404e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape=torch.Size([5, 6, 7, 8, 42000])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "X = torch.randint(low=0, high=42, size=(5, 6, 7, 8))\n",
    "embedding = nn.Embedding(num_embeddings=42, embedding_dim=42000)\n",
    "Y = embedding(X)\n",
    "print(f\"Y shape={Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxsUV8MlOXwG"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. X is a tensor of 4 dimensions, it can be thought of as containinig 5 tensors, where each tensor has a 3-D shape of (6x7x8) that contains integers between 0 and 42. Y is the embedding of X that is a tensor of 5 dimensions. Each 4-Dim vector got an embedding of size 42000. This is what is represented in last dimension. \n",
    "\n",
    "2. The following is an implemenation of the embedding with only torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1645865938458,
     "user": {
      "displayName": "Dana Gorovici",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03883066315521848737"
     },
     "user_tz": -120
    },
    "id": "dRyD9N_3XwHa",
    "outputId": "a3748031-2c77-457f-e4ba-f63be65df6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X encoded shape = torch.Size([5, 6, 7, 8, 42])\n",
      "y shape is =torch.Size([5, 6, 7, 8, 42000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "new_X=one_hot(X)\n",
    "print(f'X encoded shape = {new_X.shape}')\n",
    "embeding = nn.Linear(42, 42000)\n",
    "y=embeding(new_X.float())\n",
    "print(f'y shape is ={y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg_BUBM5dq-R"
   },
   "source": [
    "3. Regarding truncated backpropagation through time (TBPTT) with a sequence length of S: State whether the following sentences are **true or false**, and explain.\n",
    "  1. TBPTT uses a modified version of the backpropagation algorithm.\n",
    "  2. To implement TBPTT we only need to limit the length of the sequence provided to the model to length S.\n",
    "  3. TBPTT allows the model to learn relations between input that are at most S timesteps apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vB-s8bxPBqJ"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. True: TBPTT is a form of backpropogation with an additional variable. is a modified version of the BPTT training algorithm for recurrent neural networks where the sequence is processed one timestep at a time and periodically (k1 timesteps) the BPTT update is performed back for a fixed number of timesteps (k2 timesteps). \n",
    "2. False: We also need to limit the timesteps for BPTT\n",
    "3. False: We can also learn relations between inputs that are farther than S timesteps apart since a model like LSTM has a memory gate to learn more distant relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRLN2mCodq-R"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5GHHyYHdq-R"
   },
   "source": [
    "1. In tutorial 5 we learned how to use attention to perform alignment between a source and target sequence in machine translation.\n",
    "  1. Explain qualitatively what the addition of the attention mechanism between the encoder and decoder does to the hidden states that the encoder and decoder each learn to generate (for their language). How are these hidden states different from the model without attention?\n",
    "  \n",
    "  2. After learning that self-attention is gaining popularity thanks to the transformer models, you decide to change the model from the tutorial: instead of the queries being equal to the decoder hidden states, you use self-attention, so that the keys, queries and values are all equal to the encoder's hidden states (with learned projections, like in the tutorial..). What influence do you expect this will have on the learned hidden states?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nl4UoXp6Quku"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. Attention is proposed as a solution to the limitation of the Encoder-Decoder model encoding the input sequence to one fixed length vector from which to decode each output time step. This is more relevant when we have long-term dependencies, more of the hidden state need learn the dependencies and less for understanding the meaning. Here the problem is adversery while we have 2 tasks for one learning model and the attention mechanism that deals with this problem.\n",
    "The attention mechanism uses a weighted sum of all of the encoder hidden states to flexibly focus the attention of the decoder to the most relevant parts of the input sequence instead of decode all parts in a sequence. \n",
    "\n",
    "2. The self-attention mechanism allows the inputs to interact with each other and find out who they should pay more attention to. The outputs are aggregates of these interactions and attention scores, in our case we expect the learned hidden states will lead the decoder to generate words into consideration to the previous word in the sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSaVtwsadq-R"
   },
   "source": [
    "### Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvLzQjkIdq-R"
   },
   "source": [
    "1. As we have seen, a variational autoencoder's loss is comprised of a reconstruction term and  a KL-divergence term. While training your VAE, you accidentally forgot to include the KL-divergence term.\n",
    "What would be the qualitative effect of this on:\n",
    "\n",
    "  1. Images reconstructed by the model during training ($x\\to z \\to x'$)?\n",
    "  1. Images generated by the model ($z \\to x'$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTIS6iZDdg4r"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. KL-divergence will not effect the image reconstaction because it is a measure of divergence between two distributions over the same variable x and helps the model to learn the latent space distribution of each variable.\n",
    "\n",
    "2. KL-divergence will effect the image generation of the model which is generate the images according to the latent space distribution. The model without the KL-divergence is less variability in the generated x' since it's not based on probability functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKGiydfadq-S"
   },
   "source": [
    "2. Regarding VAEs, state whether each of the following statements is **true or false**, and explain:\n",
    "  1. The latent-space distribution generated by the model for a specific input image is $\\mathcal{N}(\\vec{0},\\vec{I})$.\n",
    "  2. If we feed the same image to the encoder multiple times, then decode each result, we'll get the same reconstruction.\n",
    "  3. Since the real VAE loss term is intractable, what we actually minimize instead is it's upper bound, in the hope that the bound is tight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjxC29vPg9vD"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. True: It is normally distributed with mean 0, std I. This is related to the KL-divergence\n",
    "2. False: This is because of the input of the decoder that was defined in normal distribution. the results will be vary within the values of the normal distribution with mean and std\n",
    "3. False: We are maximixing the lower bound and hoping the bound is tight. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeccIzQpdq-S"
   },
   "source": [
    "3. Regarding GANs, state whether each of the following statements is **true or false**, and explain:\n",
    "  1. Ideally, we want the generator's loss to be low, and the discriminator's loss to be high so that it's fooled well by the generator.\n",
    "  2. It's crucial to backpropagate into the generator when training the discriminator.\n",
    "  3. To generate a new image, we can sample a latent-space vector from $\\mathcal{N}(\\vec{0},\\vec{I})$.\n",
    "  4. It can be beneficial for training the generator if the discriminator is trained for a few epochs first, so that it's output isn't arbitrary.\n",
    "  5. If the generator is generating plausible images and the discriminator reaches a stable state where it has 50% accuracy (for both image types), training the generator more will further improve the generated images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qadremrh5oN"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. False: We want both losses to be small. But there is a tradeoff since minimizing one loss maximizes the other.\n",
    "2. False: There is no update of weights for the generator when training the discriminator. The generator weights are updated in backpropogation only when training the generator\n",
    "3. True: We take z, a random data point, the latent space vector from $\\mathcal{N}(\\vec{0},\\vec{I})$ and run it through the generator\n",
    "4. True: the descriminator will be able to distinct faster\n",
    "5. False: Training the generator further will improve the loss of the generator but it will not necessarily have an effect on the discriminator so it will not further improve generated images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxhU0JEidq-S"
   },
   "source": [
    "### Detection and Segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwAIT9_5dq-S"
   },
   "source": [
    "1. What is the diffrence between IoU and Dice score? what's the diffrance between IoU and mAP?\n",
    "    shortly explain when would you use what evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnKIFHywlD-Y"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. IoU is the area of overlap between the predicted segmentation and the ground truth divided by the area of union between the predicted segmentation and the ground truth.\n",
    "Dice Coefficient is 2 * the Area of Overlap divided by the total number of pixels in both images.\n",
    "The mean Average Precision or mAP score is calculated by taking the mean AP over all classes and/or overall IoU thresholds, depending on different detection challenges that exist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFpNgGtDdq-S"
   },
   "source": [
    "2. regarding of YOLO and mask-r-CNN, witch one is one stage detector? describe the RPN outputs and the YOLO output, adress how the network produce the output and the shapes of each output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2Ki_MDcQojL"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "YOLO is the one stage detector. The output of YOLO is a bounding box. In order to obtain such output YOLO takes an image and split it into an SxS grid, where each grid cell predicts only one object. Image classification and localization is applied on each grid. If the center of an object falls into a grid cell, that grid cell is responsible for detecting that object. Each of the grid cells predicts B bounding boxes with confidence scores for those boxes. Each bounding box consists of 5 predictions: bx, by, bw, bh, and confidence.\n",
    "  Thus, output dimension will S × S × (B ∗ (1+4) + C) tensor. \n",
    "\n",
    "\n",
    "In the mask r-CNN the object detection output is done by RPN. RPN uses a CNN to generate the multiple Region of Interest(RoI) using a lightweight binary classifier. It does this using anchors boxes over the image. The classifier returns object/no-object scores. Non Max suppression is applied to Anchors with high objectness score. RPN has two outputs. One output is for “object-like” and the other is for “not object-like” in form of a probability distribution.\n",
    "Then there are 4 additional outputs per anchor box (x,y,w,h). \n",
    "Thus, output dimension will be: k(4 + 2)\n",
    "Where k = number of anchor boxes, 2 are the object-like and not object-like outputs, and 4 outputs per box. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part3_SummaryQuestions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
